{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word based - Generate Anime - Bidirectional - Many to one.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMh03eLUjFGWhm5WoJwPThp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yooru6/TensorFlow---GenerateText/blob/master/Word_based_Generate_Anime_Bidirectional_ManyToOne.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz009SxN6hgM",
        "colab_type": "text"
      },
      "source": [
        "# GENERATE ANiME - BIDIRECTIONAL MANY TO ONE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPVvEVdvX2lL",
        "colab_type": "code",
        "outputId": "f8b4851f-1a72-446c-a281-416e2857644a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import os\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "from tensorflow.keras.layers import LSTM, Activation, Flatten, Dropout, Dense, Embedding, TimeDistributed\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import *\n",
        "\n",
        "#!pip install -q -U tensorflow>=1.7\n",
        "print(tf.__version__)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install -q pyyaml h5py  # Required to save models in HDF5 format\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import pprint\n",
        "from collections import Counter\n",
        "import re\n",
        "#from sklearn.utils import shuffle\n",
        "\n",
        "#!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Tensorflow version 2.1.0\n",
            "2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxh2xVUkbKxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu5rW544g_FD",
        "colab_type": "text"
      },
      "source": [
        "## Download Dataset from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtzHprKVdZBN",
        "colab_type": "code",
        "outputId": "cee7c5a9-ba61-4369-c9a4-a9d152546d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "link='https://drive.google.com/open?id=1-X0LsGR2RgXBJ4YGbnLgNHKd0z9i8Fs0'\n",
        "fluff, id = link.split('=')\n",
        "print (id) # Verify that you have everything after '='"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1-X0LsGR2RgXBJ4YGbnLgNHKd0z9i8Fs0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY0ht5IJdv1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('ultimatePlot.txt')\n",
        "text=(open(\"ultimatePlot.txt\").read())\n",
        "text=text.lower()\n",
        "#print(text[:250190])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXwsnjj5ZHzF",
        "colab_type": "text"
      },
      "source": [
        "## Replace Words/chars"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsJRZnBaZNX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Replace chars/words\n",
        "#textedited=text[:450000]\n",
        "#textedited=text[:290000]\n",
        "textedited = text.replace(\"ultimate:\\n\",\"\")#normaalisti text.replace tässä kohtaan\n",
        "textedited = textedited.replace(\"n/a\",\"\")\n",
        "textedited = textedited.replace(\"N/A\",\"\")\n",
        "textedited = textedited.replace(\"<em class=de-emphasized>(from manga)</em>\",\"\")\n",
        "textedited = textedited.replace(\"<em>\",\"\")\n",
        "textedited = textedited.replace(\"</em>\",\"\")\n",
        "textedited = textedited.replace(\"<i>\",\"\")\n",
        "textedited = textedited.replace(\"</i>\",\"\")\n",
        "textedited = textedited.replace(\"<cite>\",\"\")\n",
        "textedited = textedited.replace(\"</cite>\",\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCkPYA2t07E8",
        "colab_type": "text"
      },
      "source": [
        "## Split and index words manually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFc4vxRzq528",
        "colab_type": "code",
        "outputId": "fc06b81a-9044-4f94-b9a2-6fe94f9026f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "\n",
        "#Tokenize text\n",
        "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
        "tk = WordPunctTokenizer() \n",
        "text2=tk.tokenize(textedited)\n",
        "\n",
        "#Dictionary words etc.\n",
        "countsT=Counter()\n",
        "countsT.update(text2)\n",
        "words=sorted(countsT,key=countsT.get,reverse=True)\n",
        "nb_words=len(text2)\n",
        "word2index={word: i  for i, word in enumerate(words)} # word/num\n",
        "index2word={i: word for i, word in enumerate(words)} # num/word\n",
        "\n",
        "print(len(words)) #sanat jotka esiintyy tekstissä\n",
        "print(nb_words)#Sanojen määrä yhteensä koko tekstissä\n",
        "print(len(word2index))#Word : index\n",
        "#print(index2word)#index num : word\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29457\n",
            "517569\n",
            "29457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpJxwDiVPeUy",
        "colab_type": "text"
      },
      "source": [
        "## Make X and Y value lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKxrBh3wgv0T",
        "colab_type": "code",
        "outputId": "a0b387c2-7570-494c-a3f7-77c57071b35d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#X and Y vector data. (X=1234,Y=5; X=2345,Y=6; X=3456,Y=7. etc..)\n",
        "sequence_length=4\n",
        "step=1\n",
        "def makeDataSet():\n",
        "  global x_values\n",
        "  global sequence_length\n",
        "  \n",
        "  x_list=[]\n",
        "  y_list=[]\n",
        "\n",
        "  #POPULATE LISTS\n",
        "  for i in range(0,nb_words-sequence_length,step):\n",
        "    #print(i)\n",
        "    x=text2[i:(i+sequence_length)]\n",
        "    y=text2[i+sequence_length]\n",
        "    x_list.append(x)\n",
        "    y_list.append(y)\n",
        "  return x_list,y_list\n",
        "\n",
        "x_list,y_list = makeDataSet()\n",
        "    \n",
        "print(len(x_list),' ',len(y_list))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "517565   517565\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TWe5bJtV1vQ",
        "colab_type": "code",
        "outputId": "2ef5328b-2104-44f9-9f65-ac2161f8e208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#CHECK\n",
        "print(x_list[1])\n",
        "print(y_list[1])\n",
        "\n",
        "#TRAINING DATA\n",
        "x_list=x_list[:150000]\n",
        "y_list=y_list[:150000]\n",
        "\n",
        "#TEST DATA\n",
        "x_test=x_list[300001:320000]\n",
        "y_test=y_list[300001:320000]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['okabe', 'is', 'a', 'self']\n",
            "mad\n",
            "150000\n",
            "150000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZJjBFVvPsNl",
        "colab_type": "text"
      },
      "source": [
        "## Make boolean vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qOzAiP4pfwB",
        "colab_type": "code",
        "outputId": "60eb73ed-7795-43ed-c616-89c7e131c64e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_words=len(set(words))\n",
        "x_train = np.zeros((len(x_list),sequence_length,total_words),dtype=np.bool)\n",
        "\n",
        "print(total_words)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uMqlvmalVEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.zeros((len(x_list),total_words),dtype=np.bool)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFqtG2iEkXnB",
        "colab_type": "text"
      },
      "source": [
        "## Make training set by populatining values to boolean lists\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gWr0VJUhsrG",
        "colab_type": "code",
        "outputId": "2874489a-b21a-4a97-9e8a-9c72c43099fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x_train.shape, \" \",y_train.shape)\n",
        "for i, input_word in enumerate(x_list):\n",
        "  for j, word in enumerate(input_word):\n",
        "   # print(j)\n",
        "    x_train[i,j,word2index[word]]=1\n",
        "  y_train[i,word2index[y_list[i]]]=1\n",
        "  #print(i)\n",
        "#print(y_train[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150000, 4, 29457)   (150000, 29457)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik3zfIcUBUNu",
        "colab_type": "text"
      },
      "source": [
        "## MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agEZDEZb_dqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN_SIZE=500\n",
        "HIDDEN_SIZE2=500\n",
        "HIDDEN_SIZE3=512\n",
        "BATCH_SIZE=256\n",
        "NUM_ITERATIONS=100\n",
        "NUM_EPOCHS_PER_ITERATION= 1\n",
        "NUM_PREDS_PER_EPOCHS=100\n",
        "EPOCHS_NUM=40\n",
        "\n",
        "def create_model():\n",
        "  model=Sequential()\n",
        "  model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(HIDDEN_SIZE,return_sequences=True),input_shape=(sequence_length,total_words)))\n",
        "  model.add(tf.keras.layers.Dropout(0.4))\n",
        "  model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM((HIDDEN_SIZE2))))\n",
        "  model.add(tf.keras.layers.Dropout(0.4))\n",
        "  #model.add(tf.keras.layers.Flatten(data_format=None))\n",
        "  model.add(tf.keras.layers.Dense(total_words,activation=\"softmax\"))\n",
        "  model.compile(\n",
        "  optimizer='adam',\n",
        "  loss = 'categorical_crossentropy',\n",
        "  metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KmlYdYUJQPB",
        "colab_type": "code",
        "outputId": "6f094eea-86c1-4305-f378-89215c05b005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "\n",
        "model = create_model()\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional (Bidirectional (None, 4, 1000)           119832000 \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4, 1000)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 1000)              6004000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 29457)             29486457  \n",
            "=================================================================\n",
            "Total params: 155,322,457\n",
            "Trainable params: 155,322,457\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pp0zPd0qqTu",
        "colab_type": "text"
      },
      "source": [
        "### Model:\n",
        "  textedited[:10000] rajattu data setti<br>\n",
        "  Model1:\n",
        "  LSTM(512)<br>\n",
        "  LSTM(256, activation: relu)<br>\n",
        "  dense(output,actiuvation=softmax)<br>\n",
        "  batch=128<br>\n",
        "  total_epochs=50<br>\n",
        "  Generating from seed: ['child', 'with', 'a', 'younger', 'lover.', 'the', 'rest', 'of', 'his', 'family']\n",
        "he ask to his months disobeying future his his replace and as on bounty, tomoe. tomoya. with and search for with many bandits in to love to to village jinta born the a he way to their they sent involves "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl0RJrF_mKX1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "37b05273-3f5c-4377-864e-0b4aad81a246"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "# download to google drive\n",
        "#drive.CreateFile({'id': model_file.get('id')})\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hayCIPg6QCL",
        "colab_type": "text"
      },
      "source": [
        "## FIT MODEL:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJedq7f-Lt8r",
        "colab_type": "code",
        "outputId": "bd229cee-e8a7-4c23-bfe2-fe7444211137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#x_train, y_train = shuffle(x_train, y_train)\n",
        "\n",
        "#CALLBACKS\n",
        "filepath=\"/content/gdrive/My Drive/Colab Notebooks/checkpoints/ANiME_2x500BIdrctl_epochs:{epoch:03d}-loss:{loss:.3f}-seqL:\"+str(sequence_length)+\".h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=True, period=5)\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "#LOAD MODEL\n",
        "filepath_load=\"/content/gdrive/My Drive/Colab Notebooks/checkpoints/ANiME_2x500BIdrctl_epochs:010-loss:0.809-seqL:4.h5\"\n",
        "#model.load_weights(filepath_load)\n",
        "\n",
        "# FIT MODEL AND PREDICT AFTER X EPOCHS\n",
        "for iteration in range(10):\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Iteration #: %d\" % (iteration))\n",
        "    model.fit(x_train, y_train, epochs=EPOCHS_NUM,validation_split=0.05, batch_size=BATCH_SIZE,verbose=1,callbacks=callbacks_list,shuffle=True)#4811 0.0923393\n",
        "    test_idx = np.random.randint(int(len(x_list)*0.1)) * (-1)\n",
        "    test_words = x_list[test_idx]\n",
        "    print(\"Generating from seed: %s\" % (test_words))\n",
        "    for i in range(EPOCHS_NUM*8):        \n",
        "        Xtest = np.zeros((1, sequence_length, total_words))\n",
        "        for i, ch in enumerate(test_words):\n",
        "            Xtest[0, i, word2index[ch]] = 1\n",
        "        pred = model.predict(Xtest, verbose=0)[0]\n",
        "        ypred = index2word[np.argmax(pred)]\n",
        "        print(ypred,end=' ')\n",
        "        if (ypred==\".\" or ypred == \"!\" or ypred == \"?\"):\n",
        "          print('')\n",
        "        test_words = test_words[1:] + [ypred]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "==================================================\n",
            "Iteration #: 0\n",
            "Train on 142500 samples, validate on 7500 samples\n",
            "Epoch 1/40\n",
            "142500/142500 [==============================] - 106s 745us/sample - loss: 0.8420 - accuracy: 0.7871 - val_loss: 8.5912 - val_accuracy: 0.1527\n",
            "Epoch 2/40\n",
            "142500/142500 [==============================] - 95s 670us/sample - loss: 0.7570 - accuracy: 0.8103 - val_loss: 8.6897 - val_accuracy: 0.1509\n",
            "Epoch 3/40\n",
            "142500/142500 [==============================] - 95s 670us/sample - loss: 0.6746 - accuracy: 0.8274 - val_loss: 8.9203 - val_accuracy: 0.1505\n",
            "Epoch 4/40\n",
            "142500/142500 [==============================] - 95s 669us/sample - loss: 0.6175 - accuracy: 0.8411 - val_loss: 9.1777 - val_accuracy: 0.1521\n",
            "Epoch 5/40\n",
            "142336/142500 [============================>.] - ETA: 0s - loss: 0.5666 - accuracy: 0.8524\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/Colab Notebooks/checkpoints/ANiME_2x500BIdrctl_epochs:005-loss:0.567-seqL:4.h5\n",
            "142500/142500 [==============================] - 109s 767us/sample - loss: 0.5668 - accuracy: 0.8523 - val_loss: 9.2907 - val_accuracy: 0.1537\n",
            "Epoch 6/40\n",
            "142500/142500 [==============================] - 96s 675us/sample - loss: 0.5319 - accuracy: 0.8608 - val_loss: 9.4636 - val_accuracy: 0.1505\n",
            "Epoch 7/40\n",
            "142500/142500 [==============================] - 95s 670us/sample - loss: 0.5053 - accuracy: 0.8678 - val_loss: 9.5738 - val_accuracy: 0.1489\n",
            "Epoch 8/40\n",
            "142500/142500 [==============================] - 95s 670us/sample - loss: 0.4716 - accuracy: 0.8772 - val_loss: 9.7426 - val_accuracy: 0.1489\n",
            "Epoch 9/40\n",
            "142500/142500 [==============================] - 95s 670us/sample - loss: 0.4471 - accuracy: 0.8822 - val_loss: 9.8825 - val_accuracy: 0.1509\n",
            "Epoch 10/40\n",
            "142336/142500 [============================>.] - ETA: 0s - loss: 0.4252 - accuracy: 0.8873\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/Colab Notebooks/checkpoints/ANiME_2x500BIdrctl_epochs:010-loss:0.425-seqL:4.h5\n",
            "142500/142500 [==============================] - 98s 691us/sample - loss: 0.4252 - accuracy: 0.8873 - val_loss: 10.0060 - val_accuracy: 0.1504\n",
            "Epoch 11/40\n",
            "142500/142500 [==============================] - 96s 672us/sample - loss: 0.4100 - accuracy: 0.8929 - val_loss: 10.0408 - val_accuracy: 0.1499\n",
            "Epoch 12/40\n",
            "142500/142500 [==============================] - 96s 675us/sample - loss: 0.3911 - accuracy: 0.8972 - val_loss: 10.0457 - val_accuracy: 0.1495\n",
            "Epoch 13/40\n",
            "142500/142500 [==============================] - 96s 675us/sample - loss: 0.3750 - accuracy: 0.9012 - val_loss: 10.2077 - val_accuracy: 0.1505\n",
            "Epoch 14/40\n",
            "142500/142500 [==============================] - 96s 675us/sample - loss: 0.3647 - accuracy: 0.9033 - val_loss: 10.1524 - val_accuracy: 0.1539\n",
            "Epoch 15/40\n",
            "142336/142500 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.9063\n",
            "Epoch 00015: saving model to /content/gdrive/My Drive/Colab Notebooks/checkpoints/ANiME_2x500BIdrctl_epochs:015-loss:0.353-seqL:4.h5\n",
            "142500/142500 [==============================] - 99s 696us/sample - loss: 0.3531 - accuracy: 0.9063 - val_loss: 10.2899 - val_accuracy: 0.1487\n",
            "Epoch 16/40\n",
            "142500/142500 [==============================] - 96s 672us/sample - loss: 0.3403 - accuracy: 0.9098 - val_loss: 10.4214 - val_accuracy: 0.1499\n",
            "Epoch 17/40\n",
            "142500/142500 [==============================] - 96s 671us/sample - loss: 0.3345 - accuracy: 0.9120 - val_loss: 10.4550 - val_accuracy: 0.1471\n",
            "Epoch 18/40\n",
            "142500/142500 [==============================] - 96s 671us/sample - loss: 0.3225 - accuracy: 0.9154 - val_loss: 10.6344 - val_accuracy: 0.1488\n",
            "Epoch 19/40\n",
            "142500/142500 [==============================] - 96s 671us/sample - loss: 0.3117 - accuracy: 0.9179 - val_loss: 10.7679 - val_accuracy: 0.1503\n",
            "Epoch 20/40\n",
            "142336/142500 [============================>.] - ETA: 0s - loss: 0.3039 - accuracy: 0.9194\n",
            "Epoch 00020: saving model to /content/gdrive/My Drive/Colab Notebooks/checkpoints/ANiME_2x500BIdrctl_epochs:020-loss:0.304-seqL:4.h5\n",
            "142500/142500 [==============================] - 99s 692us/sample - loss: 0.3039 - accuracy: 0.9194 - val_loss: 10.8211 - val_accuracy: 0.1449\n",
            "Epoch 21/40\n",
            "142500/142500 [==============================] - 96s 671us/sample - loss: 0.2988 - accuracy: 0.9213 - val_loss: 10.7368 - val_accuracy: 0.1479\n",
            "Epoch 22/40\n",
            "142500/142500 [==============================] - 96s 670us/sample - loss: 0.2915 - accuracy: 0.9229 - val_loss: 10.8673 - val_accuracy: 0.1481\n",
            "Epoch 23/40\n",
            "142500/142500 [==============================] - 95s 670us/sample - loss: 0.2876 - accuracy: 0.9246 - val_loss: 10.8254 - val_accuracy: 0.1460\n",
            "Epoch 24/40\n",
            "142500/142500 [==============================] - 95s 669us/sample - loss: 0.2786 - accuracy: 0.9262 - val_loss: 10.9406 - val_accuracy: 0.1455\n",
            "Epoch 25/40\n",
            "142336/142500 [============================>.] - ETA: 0s - loss: 0.2737 - accuracy: 0.9280\n",
            "Epoch 00025: saving model to /content/gdrive/My Drive/Colab Notebooks/checkpoints/ANiME_2x500BIdrctl_epochs:025-loss:0.274-seqL:4.h5\n",
            "142500/142500 [==============================] - 99s 693us/sample - loss: 0.2740 - accuracy: 0.9279 - val_loss: 11.0361 - val_accuracy: 0.1425\n",
            "Epoch 26/40\n",
            "142500/142500 [==============================] - 96s 671us/sample - loss: 0.2708 - accuracy: 0.9281 - val_loss: 11.0051 - val_accuracy: 0.1467\n",
            "Epoch 27/40\n",
            "142500/142500 [==============================] - 96s 671us/sample - loss: 0.2622 - accuracy: 0.9298 - val_loss: 11.1187 - val_accuracy: 0.1451\n",
            "Epoch 28/40\n",
            "142500/142500 [==============================] - 96s 673us/sample - loss: 0.2580 - accuracy: 0.9309 - val_loss: 11.1903 - val_accuracy: 0.1476\n",
            "Epoch 29/40\n",
            "142500/142500 [==============================] - 96s 671us/sample - loss: 0.2515 - accuracy: 0.9330 - val_loss: 11.1904 - val_accuracy: 0.1491\n",
            "Epoch 30/40\n",
            "142336/142500 [============================>.] - ETA: 0s - loss: 0.2532 - accuracy: 0.9329\n",
            "Epoch 00030: saving model to /content/gdrive/My Drive/Colab Notebooks/checkpoints/ANiME_2x500BIdrctl_epochs:030-loss:0.253-seqL:4.h5\n",
            "142500/142500 [==============================] - 99s 694us/sample - loss: 0.2531 - accuracy: 0.9329 - val_loss: 11.2003 - val_accuracy: 0.1429\n",
            "Epoch 31/40\n",
            "142500/142500 [==============================] - 96s 677us/sample - loss: 0.2508 - accuracy: 0.9320 - val_loss: 11.0152 - val_accuracy: 0.1505\n",
            "Epoch 32/40\n",
            "142500/142500 [==============================] - 96s 676us/sample - loss: 0.2454 - accuracy: 0.9342 - val_loss: 11.3257 - val_accuracy: 0.1488\n",
            "Epoch 33/40\n",
            "142500/142500 [==============================] - 96s 676us/sample - loss: 0.2417 - accuracy: 0.9347 - val_loss: 11.1941 - val_accuracy: 0.1459\n",
            "Epoch 34/40\n",
            "142500/142500 [==============================] - 96s 675us/sample - loss: 0.2352 - accuracy: 0.9363 - val_loss: 11.3172 - val_accuracy: 0.1477\n",
            "Epoch 35/40\n",
            "142336/142500 [============================>.] - ETA: 0s - loss: 0.2300 - accuracy: 0.9383\n",
            "Epoch 00035: saving model to /content/gdrive/My Drive/Colab Notebooks/checkpoints/ANiME_2x500BIdrctl_epochs:035-loss:0.230-seqL:4.h5\n",
            "142500/142500 [==============================] - 99s 692us/sample - loss: 0.2301 - accuracy: 0.9383 - val_loss: 11.2886 - val_accuracy: 0.1504\n",
            "Epoch 36/40\n",
            "142500/142500 [==============================] - 96s 673us/sample - loss: 0.2277 - accuracy: 0.9392 - val_loss: 11.4292 - val_accuracy: 0.1473\n",
            "Epoch 37/40\n",
            "142500/142500 [==============================] - 96s 672us/sample - loss: 0.2308 - accuracy: 0.9373 - val_loss: 11.4820 - val_accuracy: 0.1436\n",
            "Epoch 38/40\n",
            "142500/142500 [==============================] - 96s 673us/sample - loss: 0.2255 - accuracy: 0.9380 - val_loss: 11.5205 - val_accuracy: 0.1456\n",
            "Epoch 39/40\n",
            "142500/142500 [==============================] - 96s 673us/sample - loss: 0.2211 - accuracy: 0.9393 - val_loss: 11.6737 - val_accuracy: 0.1477\n",
            "Epoch 40/40\n",
            "142336/142500 [============================>.] - ETA: 0s - loss: 0.2198 - accuracy: 0.9404\n",
            "Epoch 00040: saving model to /content/gdrive/My Drive/Colab Notebooks/checkpoints/ANiME_2x500BIdrctl_epochs:040-loss:0.220-seqL:4.h5\n",
            "142500/142500 [==============================] - 99s 693us/sample - loss: 0.2199 - accuracy: 0.9403 - val_loss: 11.5822 - val_accuracy: 0.1461\n",
            "Generating from seed: ['the', 'best', 'of', 'the']\n",
            "world , rin ogata was a promising up - and - comming ballet dancer , but suffered a serious injury and decided to quit . \n",
            "years later in college she comes across a strange surge of \" aer \". yuri lowell and flynn scifo are two new members fresh out of the academy of this knight division . \n",
            "both are childhood friends who went separate ways , but ended up meeting each other once again while enlisting to serve the empire . \n",
            "sara , the daughter of a dragon and a retired dragonslaying knight — sets out on a journey into the real world . \n",
            "she gradually changes as she encounters new friends and places . \n",
            "but strange events start happening revolving around the mystery of \" legacy of the 20 - faces \". so chiko has to move forward , regardless on how checkered her life will become . \n",
            "one day , she dreams of a mysterious flowering tree that wilted , causing the sprites to disappear . \n",
            "when she transfers to myodou academy , the sprites that she saw in that dream appeared before her . \n",
            "the sprites begged tsubomi to become pretty cure to protect what is really valuable . \n",
            "two years after the end of the world . \n",
            "frustrated by the multitude of problems at school and at home , nobita wonders if his life would be easier if magic really existed . \n",
            "he then asks doraemon for his what - if - telephone - booth gadget which allows both to go to a summer trip , for relaxation and ideas for the festival . \n",
            "their plans though quickly go wrong when the area they where to visit is under heavy rain and they are caught unprepared . \n",
            "forced to change their hotels , they learn that wherever they go they have fun as good friends , location doesn ’ t matter . \n",
            "the setting "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c10fn-0nD_MM",
        "colab_type": "text"
      },
      "source": [
        "## NOTES:\n",
        "start:\n",
        "\n",
        "#### TRY 1:<br>\n",
        "batchsize 256<br>\n",
        "/content/gdrive/My Drive/Colab Notebooks/checkpoints/ANiME_2x500BIdrctl_epochs:005-loss:4.781-seqL:4.h5:<br>\n",
        "10 epochs: .<br>\n",
        "\n",
        "Generating from seed: ['of', 'judoh', ',', 'claire']\n",
        "leonelli has inherited leadership of the mafia group \" vampire \" following the death of his family . \n",
        "in the city of shinjuku , a conflict between the two . \n",
        "the sequel is set off to save yuzu from shuren ( the commander of the denizens that kidnapped ichigo ' s sisters ). it is the way to find her in order to protect wako agemaki , girl who saved his life and is one of the four\n",
        "\n",
        "30 epochs:<br>\n",
        "Generating from seed: ['are', 'you', 'going', 'to']\n",
        "be living with them , into a respectable young lady . \n",
        "she agrees to make their living expenses free of charge if they succeed , but if they fail , she ' ll triple their rent . \n",
        "due to their confidence in knowing how to deal with women , they agree to make a contract with a strange boy named goku . \n",
        "the two then set off together , bulma in search of the dragonballs and goku on a quest to free all the minds trapped in aincrad . \n",
        "grimm masterpiece theatre was japanese interpretations of the old grimm ' s fairy tales . \n",
        "this series covers fairy tales that are well known to lesser known tales like \" puss ' n boots \", \" snow white \", \" cinderella \", and \" hansel and gretel \". this is the story of the medicine seller from the \" bakeneko \" arc of \" ayakashi ,\" as he continues to face various dangerous spirits . \n",
        "takashi natsume sees spirits , and with the help of a ninja girl and a mysterious raven hair woman . \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LScJA1Mu41yF",
        "colab_type": "text"
      },
      "source": [
        "## TEST MODELS:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OqvVDC4E2wP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "dfff796f-6507-4fd2-99de-55abfa6475dc"
      },
      "source": [
        " filepath_load=\"/content/gdrive/My Drive/Colab Notebooks/checkpoints/ANiME_2x500BIdrctl_epochs:030-loss:0.253-seqL:4.h5\"\n",
        " model.load_weights(filepath_load)\n",
        "  \n",
        "test_idx = np.random.randint(int(len(x_list)*0.2)) * (-1)\n",
        "test_words = [\"are\",\"you\",\"going\",\"to\"]#x_list[test_idx]\n",
        "print(\"Generating from seed: %s\" % (test_words))\n",
        "for i in range(EPOCHS_NUM*5):        \n",
        "    Xtest = np.zeros((1, sequence_length, total_words))\n",
        "    for i, ch in enumerate(test_words):\n",
        "        Xtest[0, i, word2index[ch]] = 1\n",
        "    pred = model.predict(Xtest, verbose=0)[0]\n",
        "    ypred = index2word[np.argmax(pred)]\n",
        "    print(ypred,end=' ')\n",
        "    if (ypred==\".\" or ypred == \"!\" or ypred == \"?\"):\n",
        "      print('')\n",
        "    #remove first word from test list and add predicted word to end of the list\n",
        "    test_words = test_words[1:] + [ypred]\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating from seed: ['are', 'you', 'going', 'to']\n",
            "be living with them , into a respectable young lady . \n",
            "she agrees to make their living expenses free of charge if they succeed , but if they fail , she ' ll triple their rent . \n",
            "due to their confidence in knowing how to deal with women , they agree to make a contract with a strange boy named goku . \n",
            "the two then set off together , bulma in search of the dragonballs and goku on a quest to free all the minds trapped in aincrad . \n",
            "grimm masterpiece theatre was japanese interpretations of the old grimm ' s fairy tales . \n",
            "this series covers fairy tales that are well known to lesser known tales like \" puss ' n boots \", \" snow white \", \" cinderella \", and \" hansel and gretel \". this is the story of the medicine seller from the \" bakeneko \" arc of \" ayakashi ,\" as he continues to face various dangerous spirits . \n",
            "takashi natsume sees spirits , and with the help of a ninja girl and a mysterious raven hair woman . \n",
            "500 years before saiyuki , a heretic child with golden eyes is brought to heaven and "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch9gJyDX49NP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3pI8fyH5Fqb",
        "colab_type": "text"
      },
      "source": [
        "## SAVE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIYt5kdz8H0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# create on Colab directory\n",
        "model.save_weights('ESTRY_2x400BIdrctl_epochs:001-loss:0.388--seqL:4.h5')    \n",
        "model_file = drive.CreateFile({'title' : 'ESTRY_2x400BIdrctl_epochs:001-loss:0.388--seqL:4.h5'})\n",
        "model_file.SetContentFile('ESTRY_2x400BIdrctl_epochs:001-loss:0.388--seqL:4.h5')\n",
        "model_file.Upload()\n",
        "# download to google drive\n",
        "drive.CreateFile({'id': model_file.get('id')})"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}